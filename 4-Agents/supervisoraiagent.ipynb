{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3e46e6",
   "metadata": {},
   "source": [
    "# Supervisor Multi AI Agent Architecture\n",
    "* Agents are dependent on the tasks provided by the supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1187ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict, List, Literal, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import END, START,StateGraph, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition, create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd527c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining supervisor class\n",
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"State for the supervisor multi-agent system\"\"\"\n",
    "    next_agent: str = \"\"\n",
    "    research_data: str = \"\"\n",
    "    analysis: str = \"\"\n",
    "    final_report: str = \"\"\n",
    "    task_complete: bool = False\n",
    "    current_task: str = \"\"\n",
    "\n",
    "# creating supervisor chain\n",
    "def create_supervisor_chain():\n",
    "    \"\"\"creates a supervisor decision chain\"\"\"\n",
    "    supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\"You are a supervisor managing a team of agents:\n",
    "            \n",
    "            1. Researcher - Gathers information and data\n",
    "            2. Analyst - Analyses the data and provides insights\n",
    "            3. Writer - Creates reports and summaries\n",
    "\n",
    "            Based on the current state and conversation , decide which agent should work next.\n",
    "            If the task is completed, respond with 'Done'.\n",
    "\n",
    "            Current state:\n",
    "            - Has research data : {has_research}\n",
    "            - Has analysis : {has_analysis}\n",
    "            - Has report : {has_report}\n",
    "\n",
    "            Respond with ONLY the agent name (researcher/analyst/writer) or 'Done'.\n",
    "        \"\"\" ),\n",
    "        (\"human\",\"{task}\")\n",
    "    ])\n",
    "\n",
    "    return supervisor_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6b4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating supervisor node\n",
    "def supervisor_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Supervisor decides which is the next agent to call using Groq LLM\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    task = messages[-1].content if messages else \"No task\"\n",
    "\n",
    "    # Check whats been completed\n",
    "    has_research = bool(state.get(\"research_data\", \"\"))\n",
    "    has_analysis = bool(state.get(\"analysis\", \"\"))\n",
    "    has_report = bool(state.get(\"final_report\", \"\"))\n",
    "\n",
    "    # Get LLM message\n",
    "    chain = create_supervisor_chain()\n",
    "    decision = chain.invoke({\n",
    "        \"task\": task,\n",
    "        \"has_research\": has_research,\n",
    "        \"has_analysis\": has_analysis,\n",
    "        \"has_report\": has_report\n",
    "    })\n",
    "\n",
    "    # Parse decision\n",
    "    decision_text = decision.content.strip().lower()\n",
    "    print(decision_text)\n",
    "\n",
    "    # Determine next agent\n",
    "    if \"done\" in decision_text or has_report:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"Supervisor: All tasks have been completed! Great work team!\"\n",
    "    elif \"researcher\" in decision_text or not has_research:\n",
    "        next_agent = \"researcher\"\n",
    "        supervisor_msg = \"Supervisor: Let's start with research. Assigning the task to Researcher....\"\n",
    "    elif \"analyst\" in decision_text or (has_research and not has_analysis):\n",
    "        next_agent = \"analyst\"\n",
    "        supervisor_msg = \"Supervisor: Research done. Time for analysis. Assigning to Analyst...\"\n",
    "    elif \"writer\" in decision_text or (has_analysis and not has_report):\n",
    "        next_agent = \"writer\"\n",
    "        supervisor_msg = \"Supervisor: Analysis done. Let's create the report. Assigning to writer\"\n",
    "    else:\n",
    "        next_agent = \"end\"\n",
    "        supervisor_msg = \"Supervisor: Tasks seems complete\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=supervisor_msg)],\n",
    "        \"next_agent\":next_agent,\n",
    "        \"current_task\": task\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befefdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating writer agent\n",
    "def writer_agent(state: SupervisorState) -> Dict:\n",
    "    \"\"\"Writer agent uses Groq to write the final report\"\"\"\n",
    "\n",
    "    research_data = state.get(\"research_data\", \"\")\n",
    "    analysis = state.get(\"analysis\", \"\")\n",
    "    task = state.get(\"current_task\", \"\")\n",
    "\n",
    "    # writing prompt\n",
    "    writing_prompt = f\"\"\"As a professional writer, create an executive report based on:\n",
    "    Task : {task}\n",
    "\n",
    "    Research Findings:\n",
    "    {research_data[:1000]}\n",
    "\n",
    "    Analysis Findings:\n",
    "    {analysis[:1000]}\n",
    "\n",
    "    Create a well-structured report with:\n",
    "    1. Executive Summary\n",
    "    2. Key Findings\n",
    "    3. Analysis & Insights\n",
    "    4. Recommendations\n",
    "    5. Conclusion\n",
    "\n",
    "    Keep it professional and concise.\"\"\"\n",
    "\n",
    "    # Get report from LLM\n",
    "    report_response = llm.invoke([HumanMessage(content = writing_prompt)])\n",
    "    report = report_response.content\n",
    "\n",
    "    # create final formatted report\n",
    "    final_report = f\"\"\"\n",
    "    FINAL REPORT\n",
    "    {'='*50}\n",
    "    Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "    Topic: {task}\n",
    "    {'='*50}\n",
    "\n",
    "    {report}\n",
    "\n",
    "    {'='*50}\n",
    "    Report compiled by Multi-AI Agent system powered by Groq\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\":[AIMessage(content=f\"Writer: Report complete! See below for the full document.\")],\n",
    "        \"final_report\": final_report,\n",
    "        \"next_agent\": \"supervisor\",\n",
    "        \"task_complete\": True\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8a66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d8996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f5ccf0b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgentLangGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
